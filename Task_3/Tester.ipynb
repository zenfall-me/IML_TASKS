{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embedding #0 done!\n",
      "Image embedding #1 done!\n",
      "Image embedding #2 done!\n",
      "Image embedding #3 done!\n",
      "Image embedding #4 done!\n",
      "Image embedding #5 done!\n",
      "Image embedding #6 done!\n",
      "Image embedding #7 done!\n",
      "Image embedding #8 done!\n",
      "Image embedding #9 done!\n",
      "Image embedding #10 done!\n",
      "Image embedding #11 done!\n",
      "Image embedding #12 done!\n",
      "Image embedding #13 done!\n",
      "Image embedding #14 done!\n",
      "Image embedding #15 done!\n",
      "Image embedding #16 done!\n",
      "Image embedding #17 done!\n",
      "Image embedding #18 done!\n",
      "Image embedding #19 done!\n",
      "Image embedding #20 done!\n",
      "Image embedding #21 done!\n",
      "Image embedding #22 done!\n",
      "Image embedding #23 done!\n",
      "Image embedding #24 done!\n",
      "Image embedding #25 done!\n",
      "Image embedding #26 done!\n",
      "Image embedding #27 done!\n",
      "Image embedding #28 done!\n",
      "Image embedding #29 done!\n",
      "Image embedding #30 done!\n",
      "Image embedding #31 done!\n",
      "Image embedding #32 done!\n",
      "Image embedding #33 done!\n",
      "Image embedding #34 done!\n",
      "Image embedding #35 done!\n",
      "Image embedding #36 done!\n",
      "Image embedding #37 done!\n",
      "Image embedding #38 done!\n",
      "Image embedding #39 done!\n",
      "Image embedding #40 done!\n",
      "Image embedding #41 done!\n",
      "Image embedding #42 done!\n",
      "Image embedding #43 done!\n",
      "Image embedding #44 done!\n",
      "Image embedding #45 done!\n",
      "Image embedding #46 done!\n",
      "Image embedding #47 done!\n",
      "Image embedding #48 done!\n",
      "Image embedding #49 done!\n",
      "Image embedding #50 done!\n",
      "Image embedding #51 done!\n",
      "Image embedding #52 done!\n",
      "Image embedding #53 done!\n",
      "Image embedding #54 done!\n",
      "Image embedding #55 done!\n",
      "Image embedding #56 done!\n",
      "Image embedding #57 done!\n",
      "Image embedding #58 done!\n",
      "Image embedding #59 done!\n",
      "Image embedding #60 done!\n",
      "Image embedding #61 done!\n",
      "Image embedding #62 done!\n",
      "Image embedding #63 done!\n",
      "Image embedding #64 done!\n",
      "Image embedding #65 done!\n",
      "Image embedding #66 done!\n",
      "Image embedding #67 done!\n",
      "Image embedding #68 done!\n",
      "Image embedding #69 done!\n",
      "Image embedding #70 done!\n",
      "Image embedding #71 done!\n",
      "Image embedding #72 done!\n",
      "Image embedding #73 done!\n",
      "Image embedding #74 done!\n",
      "Image embedding #75 done!\n",
      "Image embedding #76 done!\n",
      "Image embedding #77 done!\n",
      "Image embedding #78 done!\n",
      "Image embedding #79 done!\n",
      "Image embedding #80 done!\n",
      "Image embedding #81 done!\n",
      "Image embedding #82 done!\n",
      "Image embedding #83 done!\n",
      "Image embedding #84 done!\n",
      "Image embedding #85 done!\n",
      "Image embedding #86 done!\n",
      "Image embedding #87 done!\n",
      "Image embedding #88 done!\n",
      "Image embedding #89 done!\n",
      "Image embedding #90 done!\n",
      "Image embedding #91 done!\n",
      "Image embedding #92 done!\n",
      "Image embedding #93 done!\n",
      "Image embedding #94 done!\n",
      "Image embedding #95 done!\n",
      "Image embedding #96 done!\n",
      "Image embedding #97 done!\n",
      "Image embedding #98 done!\n",
      "Image embedding #99 done!\n",
      "Image embedding #100 done!\n",
      "Image embedding #101 done!\n",
      "Image embedding #102 done!\n",
      "Image embedding #103 done!\n",
      "Image embedding #104 done!\n",
      "Image embedding #105 done!\n",
      "Image embedding #106 done!\n",
      "Image embedding #107 done!\n",
      "Image embedding #108 done!\n",
      "Image embedding #109 done!\n",
      "Image embedding #110 done!\n",
      "Image embedding #111 done!\n",
      "Image embedding #112 done!\n",
      "Image embedding #113 done!\n",
      "Image embedding #114 done!\n",
      "Image embedding #115 done!\n",
      "Image embedding #116 done!\n",
      "Image embedding #117 done!\n",
      "Image embedding #118 done!\n",
      "Image embedding #119 done!\n",
      "Image embedding #120 done!\n",
      "Image embedding #121 done!\n",
      "Image embedding #122 done!\n",
      "Image embedding #123 done!\n",
      "Image embedding #124 done!\n",
      "Image embedding #125 done!\n",
      "Image embedding #126 done!\n",
      "Image embedding #127 done!\n",
      "Image embedding #128 done!\n",
      "Image embedding #129 done!\n",
      "Image embedding #130 done!\n",
      "Image embedding #131 done!\n",
      "Image embedding #132 done!\n",
      "Image embedding #133 done!\n",
      "Image embedding #134 done!\n",
      "Image embedding #135 done!\n",
      "Image embedding #136 done!\n",
      "Image embedding #137 done!\n",
      "Image embedding #138 done!\n",
      "Image embedding #139 done!\n",
      "Image embedding #140 done!\n",
      "Image embedding #141 done!\n",
      "Image embedding #142 done!\n",
      "Image embedding #143 done!\n",
      "Image embedding #144 done!\n",
      "Image embedding #145 done!\n",
      "Image embedding #146 done!\n",
      "Image embedding #147 done!\n",
      "Image embedding #148 done!\n",
      "Image embedding #149 done!\n",
      "Image embedding #150 done!\n",
      "Image embedding #151 done!\n",
      "Image embedding #152 done!\n",
      "Image embedding #153 done!\n",
      "Image embedding #154 done!\n",
      "Image embedding #155 done!\n",
      "Image embedding #156 done!\n",
      "Fetching data...\n",
      "Key 02461 not found in file_to_embedding\n",
      "Key 03450 not found in file_to_embedding\n",
      "Key 02678 not found in file_to_embedding\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'02461'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 414\u001B[0m\n\u001B[0;32m    411\u001B[0m \u001B[38;5;66;03m# load the training and testing data\u001B[39;00m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFetching data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 414\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTRAIN_TRIPLETS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    415\u001B[0m X_test, _ \u001B[38;5;241m=\u001B[39m get_data(TEST_TRIPLETS, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    417\u001B[0m \u001B[38;5;66;03m# Create data loaders for the training and testing data\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[19], line 136\u001B[0m, in \u001B[0;36mget_data\u001B[1;34m(file, train)\u001B[0m\n\u001B[0;32m    134\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m a \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m file_to_embedding:\n\u001B[0;32m    135\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ma\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in file_to_embedding\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 136\u001B[0m     emb \u001B[38;5;241m=\u001B[39m [file_to_embedding[a] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39msplit()]\n\u001B[0;32m    138\u001B[0m emb \u001B[38;5;241m=\u001B[39m [file_to_embedding[a] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39msplit()]\n\u001B[0;32m    139\u001B[0m X\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mhstack([emb[\u001B[38;5;241m0\u001B[39m], emb[\u001B[38;5;241m1\u001B[39m], emb[\u001B[38;5;241m2\u001B[39m]]))\n",
      "Cell \u001B[1;32mIn[19], line 136\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    134\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m a \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m file_to_embedding:\n\u001B[0;32m    135\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ma\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in file_to_embedding\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 136\u001B[0m     emb \u001B[38;5;241m=\u001B[39m [\u001B[43mfile_to_embedding\u001B[49m\u001B[43m[\u001B[49m\u001B[43ma\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39msplit()]\n\u001B[0;32m    138\u001B[0m emb \u001B[38;5;241m=\u001B[39m [file_to_embedding[a] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39msplit()]\n\u001B[0;32m    139\u001B[0m X\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39mhstack([emb[\u001B[38;5;241m0\u001B[39m], emb[\u001B[38;5;241m1\u001B[39m], emb[\u001B[38;5;241m2\u001B[39m]]))\n",
      "\u001B[1;31mKeyError\u001B[0m: '02461'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# %%\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# %%\n",
    "def generate_embeddings():\n",
    "    \"\"\"\n",
    "    Transform, resize and normalize the images and then use a pretrained model to extract\n",
    "    the embeddings.\n",
    "    \"\"\"\n",
    "    # TODO: define a transform to pre-process the images for ResNet50\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load the images and apply the pre-process transform\n",
    "    train_dataset = datasets.ImageFolder(root=\"dataset/\", transform=train_transforms)\n",
    "    # Hint: adjust batch_size and num_workers to your PC configuration, so that you don't\n",
    "    # run out of memory\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=64,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True, num_workers=4)\n",
    "\n",
    "    # TODO: define a model for extraction of the embeddings (Hint: load a pretrained model,\n",
    "    #  more info here: https://pytorch.org/vision/stable/models.html)\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights)\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()  # put model in evaluation mode in case it uses dropout and batch normalization layers\n",
    "\n",
    "    embedding_size = 2048\n",
    "    num_images = len(train_dataset)\n",
    "    embeddings = []\n",
    "    # embeddings = np.zeros((num_images, embedding_size))\n",
    "\n",
    "    # TODO: Use the model to extract the embeddings. Hint: remove the last layers of the\n",
    "    # model to access the embeddings the model generates.\n",
    "\n",
    "    # Remove last layer\n",
    "    model.fc = torch.nn.Sequential()\n",
    "\n",
    "    # Pass the data to the model to get the embedding\n",
    "    for idx, (data_batch, target) in enumerate(train_loader):\n",
    "        output_batch = model(data_batch).cpu().detach().numpy()  # get embedding per batch and convert to numpy array\n",
    "        # iterate over batch and write each embedding to embeddings\n",
    "        for output in output_batch:  # iterates over first dimension of tensor of shape (batch_size, 2048, 1, 1)\n",
    "            embeddings.append(np.squeeze(output))  # remove superfluouse dimensions by squeezig and save embedding\n",
    "        print(\"Image embedding #{} done!\".format(idx))\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "\n",
    "    np.save('dataset/embeddings.npy', embeddings)\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_data(file, train=True):\n",
    "    \"\"\"\n",
    "    Load the triplets from the file and generate the features and labels.\n",
    "\n",
    "    input: file: string, the path to the file containing the triplets\n",
    "          train: boolean, whether the data is for training or testing\n",
    "\n",
    "    output: X: numpy array, the features\n",
    "            y: numpy array, the labels\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            triplets.append(line)\n",
    "\n",
    "    # generate training data from triplets\n",
    "    train_dataset = datasets.ImageFolder(root=\"dataset/\",\n",
    "                                         transform=None)\n",
    "    filenames = [s[0].split('/')[-1].replace('.jpg', '') for s in train_dataset.samples]\n",
    "    embeddings = np.load('dataset/embeddings.npy')\n",
    "\n",
    "    # TODO: Normalize the embeddings across the dataset\n",
    "    \"\"\"\n",
    "    # Calculate mean and standard deviation along each dimension\n",
    "    mean = np.mean(embeddings, axis=0)\n",
    "    std = np.std(embeddings, axis=0)\n",
    "    # Normalize the embeddings by subtracting the mean and dividing by the standard deviation\n",
    "    normalized_embeddings = (embeddings - mean) / std\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate L2 norm for each embedding vector\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    # Normalize the embeddings by dividing by the L2 norm\n",
    "    normalized_embeddings = embeddings / norms\n",
    "\n",
    "    \"\"\"\n",
    "    # Find largest embedding\n",
    "    embedding_norms = np.zeros((embeddings.shape[0]))\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        embedding_norm = np.linalg.norm(embedding) # calculate norm of embedding\n",
    "        embedding_norms[i] = embedding_norm # remember norm\n",
    "    max_norm = embedding_norms.max() # find largest norm\n",
    "    # Normalize embeddings, s.t. largest embedding vector has size 1\n",
    "    normalized_embeddings = embeddings/max_norm\n",
    "    \"\"\"\n",
    "\n",
    "    # print(normalized_embeddings[0,0:20])\n",
    "\n",
    "    file_to_embedding = {}\n",
    "    for i in range(len(filenames)):\n",
    "        file_to_embedding[filenames[i]] = normalized_embeddings[i]\n",
    "    X = []\n",
    "    y = []\n",
    "    # use the individual embeddings to generate the features and labels for triplets\n",
    "    for t in triplets:\n",
    "        for a in t.split():\n",
    "            if a not in file_to_embedding:\n",
    "                print(f\"Key {a} not found in file_to_embedding\")\n",
    "        emb = [file_to_embedding[a] for a in t.split()]\n",
    "\n",
    "    emb = [file_to_embedding[a] for a in t.split()]\n",
    "    X.append(np.hstack([emb[0], emb[1], emb[2]]))\n",
    "    y.append(1)\n",
    "    \"\"\"\n",
    "    # Generating negative samples (data augmentation)\n",
    "    if train:\n",
    "        X.append(np.hstack([emb[0], emb[2], emb[1]]))\n",
    "        y.append(0)\n",
    "    \"\"\"\n",
    "    X = np.vstack(X)\n",
    "    y = np.hstack(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# %%\n",
    "# Hint: adjust batch_size and num_workers to your PC configuration, so that you don't run out of memory\n",
    "def create_loader_from_np(X, y=None, train=True, batch_size=64, shuffle=True, num_workers=4):\n",
    "    \"\"\"\n",
    "    Create a torch.utils.data.DataLoader object from numpy arrays containing the data.\n",
    "\n",
    "    input: X: numpy array, the features\n",
    "           y: numpy array, the labels\n",
    "\n",
    "    output: loader: torch.data.util.DataLoader, the object containing the data\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float),\n",
    "                                torch.from_numpy(y).type(torch.long))\n",
    "    else:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n",
    "    loader = DataLoader(dataset=dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle,\n",
    "                        pin_memory=True, num_workers=num_workers)\n",
    "    return loader\n",
    "\n",
    "\n",
    "# %%\n",
    "# TODO: define a model. Here, the basic structure is defined, but you need to fill in the details\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    The model class, which defines our classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The constructor of the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(2048, 1024)\n",
    "        # self.hidden_layer = nn.Linear(1024, 1024)\n",
    "        self.output_layer = nn.Linear(1024, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward pass of the model.\n",
    "\n",
    "        input: x: torch.Tensor, the input to the model\n",
    "\n",
    "        output: x: torch.Tensor, the output of the model\n",
    "        \"\"\"\n",
    "        x = self.input_layer(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.hidden_layer(x)\n",
    "        # x = F.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_accuracy(emb_image1, emb_image2, emb_image3, y, verbose=False):\n",
    "    \"\"\"\n",
    "    output: accuracy of this batch\n",
    "    \"\"\"\n",
    "    # calculate the distances between the embeddings in this batch\n",
    "    dist12 = torch.cdist(emb_image1.unsqueeze(dim=1).flatten(2), emb_image2.unsqueeze(dim=1).flatten(2)).squeeze()\n",
    "    dist13 = torch.cdist(emb_image1.unsqueeze(dim=1).flatten(2), emb_image3.unsqueeze(dim=1).flatten(2)).squeeze()\n",
    "\n",
    "    # check which distance is larger\n",
    "    diff = dist13 - dist12  # positive if distance between image 1 and 2 is smaller than distance between image 1 and 3\n",
    "    predicted = (diff > 0).long()  # 1 if diff is positive, 0 otherwise\n",
    "\n",
    "    # convert to numpy\n",
    "    predicted = predicted.cpu().detach().numpy()\n",
    "    y = y.cpu().detach().numpy()\n",
    "\n",
    "    if verbose:\n",
    "        print(y)\n",
    "        print(predicted)\n",
    "        print(y == predicted)\n",
    "    num_correct = np.sum((y == predicted).astype(int))\n",
    "    num_tot = len(y)\n",
    "\n",
    "    return num_correct / num_tot\n",
    "\n",
    "\n",
    "# %%\n",
    "def train_model(train_loader):\n",
    "    \"\"\"\n",
    "    The training procedure of the model; it accepts the training data, defines the model\n",
    "    and then trains it.\n",
    "\n",
    "    input: train_loader: torch.data.util.DataLoader, the object containing the training data\n",
    "\n",
    "    output: model: torch.nn.Module, the trained model\n",
    "    \"\"\"\n",
    "    model = Net()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    n_epochs = 1\n",
    "\n",
    "    loss_train_progress = []\n",
    "    loss_val_progress = []\n",
    "    accuracy_train_progress = []\n",
    "    accuracy_val_progress = []\n",
    "\n",
    "    # TODO: define a loss function, optimizer and proceed with training. Hint: use the part\n",
    "    # of the training data as a validation split. After each epoch, compute the loss on the\n",
    "    # validation split and print it out. This enables you to see how your model is performing\n",
    "    # on the validation data before submitting the results on the server. After choosing the\n",
    "    # best model, train it on the whole training data.\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n",
    "    triplet_loss = torch.nn.TripletMarginLoss(margin=1, p=2)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {} has started.\".format(epoch))\n",
    "        total_train_loss, total_val_loss, count_train, count_val = 0, 0, 0, 0\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        for i, [X, y] in enumerate(train_loader):\n",
    "            \"\"\"\n",
    "            # Test validation split\n",
    "            X_val = X[50:,:]\n",
    "            y_val = y[50:]\n",
    "\n",
    "            X = X[:50,:]\n",
    "            y = y[:50]\n",
    "            \"\"\"\n",
    "\n",
    "            # Test set\n",
    "            # create embedding and apply triplet loss\n",
    "            anchor = model(X[:, :2048])\n",
    "            positive = model(X[:, 2048:4096])\n",
    "            negative = model(X[:, 4096:6144])\n",
    "            loss = triplet_loss(anchor, positive, negative)\n",
    "\n",
    "            # keep track of progress\n",
    "            total_train_loss += loss\n",
    "            count_train += len(y)\n",
    "            train_accuracies.append(get_accuracy(anchor, positive, negative, y))\n",
    "\n",
    "            # optimize model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \"\"\"\n",
    "            # Validation set\n",
    "            val_anchor = model(X_val[:,:2048])\n",
    "            val_positive = model(X_val[:,2048:4096])\n",
    "            val_negative = model(X_val[:,4096:6144])\n",
    "            val_loss = triplet_loss(val_anchor, val_positive, val_negative)\n",
    "            total_val_loss += val_loss\n",
    "            count_val += len(y_val)\n",
    "            val_accuracies.append(get_accuracy(val_anchor, val_positive, val_negative, y_val))\n",
    "            \"\"\"\n",
    "        # average accuracies over this epoch\n",
    "        train_accuracy = np.average(np.hstack(train_accuracies))\n",
    "        # val_accuracy = np.average(np.hstack(val_accuracies))\n",
    "\n",
    "        # Clear the previous output\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "        # calculate and print progress\n",
    "        total_train_loss = total_train_loss.item() / count_train\n",
    "        loss_train_progress.append(total_train_loss)\n",
    "        print(\"Training loss in epoch {} is: {}\".format(epoch, total_train_loss))\n",
    "\n",
    "        accuracy_train_progress.append(train_accuracy)\n",
    "        print(\"Training accuracy in epoch {} is: {}\".format(epoch, train_accuracy))\n",
    "        \"\"\"\n",
    "        total_val_loss = total_val_loss.item()/count_val\n",
    "        loss_val_progress.append(total_val_loss)\n",
    "        print(\"Validation loss in epoch {} is: {}\".format(epoch, total_val_loss))\n",
    "\n",
    "        accuracy_val_progress.append(val_accuracy)\n",
    "        print(\"Validation accuracy in epoch {} is: {}\".format(epoch, val_accuracy))\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Create an empty plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        ax1.set_title('Loss')\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax1.set_xlabel('Epochs')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "\n",
    "        # Clear the previous plot\n",
    "        #ax1.cla()\n",
    "        #ax2.cla()\n",
    "\n",
    "        # Plot the updated data points\n",
    "        ax1.plot(loss_train_progress, color='red', label='Training Loss')\n",
    "        #ax1.plot(loss_val_progress, color='blue', label='Validation Loss')\n",
    "        ax2.plot(accuracy_train_progress, color='red', label='Training Accuracy')\n",
    "        #ax2.plot(accuracy_val_progress, color='blue', label='Validation Accuracy')\n",
    "        # Add legend\n",
    "        ax1.legend()\n",
    "        ax2.legend()\n",
    "        # Show the plot without blocking\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "        \"\"\"\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# %%\n",
    "def test_model(model, loader):\n",
    "    \"\"\"\n",
    "    The testing procedure of the model; it accepts the testing data and the trained model and\n",
    "    then tests the model on it.\n",
    "\n",
    "    input: model: torch.nn.Module, the trained model\n",
    "           loader: torch.data.util.DataLoader, the object containing the testing data\n",
    "\n",
    "    output: None, the function saves the predictions to a results.txt file\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad():  # We don't need to compute gradients for testing\n",
    "        for [x_batch] in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "\n",
    "            # predict embeddings\n",
    "            emb_image1 = model(x_batch[:, :2048])\n",
    "            emb_image2 = model(x_batch[:, 2048:4096])\n",
    "            emb_image3 = model(x_batch[:, 4096:6144])\n",
    "            # print(emb_image1[0])\n",
    "\n",
    "            # calculate the distances between the embeddings in this batch\n",
    "            dist12 = torch.cdist(emb_image1.unsqueeze(dim=1).flatten(2),\n",
    "                                 emb_image2.unsqueeze(dim=1).flatten(2)).squeeze()\n",
    "            dist13 = torch.cdist(emb_image1.unsqueeze(dim=1).flatten(2),\n",
    "                                 emb_image3.unsqueeze(dim=1).flatten(2)).squeeze()\n",
    "            # print(dist12.shape)\n",
    "            # print(dist13.shape)\n",
    "\n",
    "            # check which distance is larger\n",
    "            diff = dist13 - dist12  # positive if distance between image 1 and 2 is smaller than distance between image 1 and 3\n",
    "            predicted = (diff > 0).long()  # 1 if diff is positive, 0 otherwise\n",
    "            # print(diff)\n",
    "            # print(predicted.shape)\n",
    "\n",
    "            predictions.append(predicted)\n",
    "\n",
    "        predictions = np.hstack(predictions)\n",
    "    np.savetxt(\"results.txt\", predictions, fmt='%i')\n",
    "\n",
    "\n",
    "# %%\n",
    "# Main function. You don't have to change this\n",
    "if __name__ == '__main__':\n",
    "    TRAIN_TRIPLETS = 'train_triplets.txt'\n",
    "    TEST_TRIPLETS = 'test_triplets.txt'\n",
    "\n",
    "    # generate embedding for each image in the dataset\n",
    "    if (os.path.exists('dataset/embeddings.npy') == False):\n",
    "        generate_embeddings()\n",
    "\n",
    "    # load the training and testing data\n",
    "    print(\"Fetching data...\")\n",
    "\n",
    "    X, y = get_data(TRAIN_TRIPLETS)\n",
    "    X_test, _ = get_data(TEST_TRIPLETS, train=False)\n",
    "\n",
    "    # Create data loaders for the training and testing data\n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader = create_loader_from_np(X, y, train=True, batch_size=64)\n",
    "    test_loader = create_loader_from_np(X_test, train=False, batch_size=2048, shuffle=False)\n",
    "\n",
    "    # define a model and train it\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(train_loader)\n",
    "\n",
    "    # test the model on the test data\n",
    "    print(\"Testing the model...\")\n",
    "    test_model(model, test_loader)\n",
    "    print(\"Results saved to results.txt\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
