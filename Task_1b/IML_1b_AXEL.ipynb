{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This serves as a template which will guide you through the implementation of this task.  It is advised\n",
    "# to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "\n",
    "# First, we import necessary libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "\n",
    "def transform_data(X):\n",
    "    \"\"\"\n",
    "    This function transforms the 5 input features of matrix X (x_i denoting the i-th component of X)\n",
    "    into 21 new features phi(X) in the following manner:\n",
    "    5 linear features: phi_1(X) = x_1, phi_2(X) = x_2, phi_3(X) = x_3, phi_4(X) = x_4, phi_5(X) = x_5\n",
    "    5 quadratic features: phi_6(X) = x_1^2, phi_7(X) = x_2^2, phi_8(X) = x_3^2, phi_9(X) = x_4^2, phi_10(X) = x_5^2\n",
    "    5 exponential features: phi_11(X) = exp(x_1), phi_12(X) = exp(x_2), phi_13(X) = exp(x_3), phi_14(X) = exp(x_4), phi_15(X) = exp(x_5)\n",
    "    5 cosine features: phi_16(X) = cos(x_1), phi_17(X) = cos(x_2), phi_18(X) = cos(x_3), phi_19(X) = cos(x_4), phi_20(X) = cos(x_5)\n",
    "    1 constant features: phi_21(X)=1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: matrix of floats, dim = (700,5), inputs with 5 features\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_transformed: array of floats: dim = (700,21), transformed input with 21 features\n",
    "    \"\"\"\n",
    "    #resize trasform depending on training data size (Kfolded)\n",
    "    length = np.size(X,axis=0)\n",
    "    X_transformed = np.zeros((length, 21))\n",
    "\n",
    "    X_square = np.square(X)\n",
    "    X_exp = np.exp(X)\n",
    "    X_cos = np.cos(X)\n",
    "    const = np.ones((length,1))\n",
    "\n",
    "    X_transformed = np.concatenate((X, X_square, X_exp, X_cos, const), 1)\n",
    "    assert X_transformed.shape == (length, 21)\n",
    "    return X_transformed\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "\n",
    "def fit(X, y):\n",
    "    \"\"\"\n",
    "    This function receives training data points, transform them, and then fits the linear regression on this\n",
    "    transformed data. Finally, it outputs the weights of the fitted linear regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: matrix of floats, dim = (700,5), inputs with 5 features\n",
    "    y: array of floats, dim = (700,), input labels)\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    w: array of floats: dim = (21,), optimal parameters of linear regression\n",
    "    \"\"\"\n",
    "    w = np.zeros((21,))\n",
    "    X_transformed = transform_data(X)\n",
    "\n",
    "    regr = ElasticNetCV(cv=100, random_state=0, fit_intercept=False, max_iter = 10000)\n",
    "    regr.fit(X_transformed, y)\n",
    "    w = regr.coef_\n",
    "\n",
    "    assert w.shape == (21,)\n",
    "    return w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def calculate_RMSE(w, X, y):\n",
    "    \"\"\"This function takes test data points (X and y), and computes the empirical RMSE of\n",
    "    predicting y from X using a linear model with weights w.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w: array of floats: dim = (13,), optimal parameters of ridge regression\n",
    "    X: matrix of floats, dim = (15,13), inputs with 13 features\n",
    "    y: array of floats, dim = (15,), input labels\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    RMSE: float: dim = 1, RMSE value\n",
    "    \"\"\"\n",
    "    td_y = y\n",
    "    td_y_pred = X w\n",
    "\n",
    "     #unsure if the **0.5 is needed or not\n",
    "    RMSE = mean_squared_error(td_y, td_y_pred) **0.5\n",
    "    assert np.isscalar(RMSE)\n",
    "    return RMSE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x1    x2    x3    x4    x5\n",
      "0  0.02  0.05 -0.09 -0.43 -0.08\n",
      "1 -0.13  0.11 -0.08 -0.29 -0.03\n",
      "2  0.08  0.06 -0.07 -0.41 -0.03\n",
      "3  0.02 -0.12  0.01 -0.43 -0.02\n",
      "4 -0.14 -0.12 -0.08 -0.02 -0.08\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ElasticNetCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m X \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# The function retrieving optimal LR parameters\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m w \u001B[38;5;241m=\u001B[39m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Save results in the required format\u001B[39;00m\n\u001B[0;32m     14\u001B[0m np\u001B[38;5;241m.\u001B[39msavetxt(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, w, fmt\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.12f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[34], line 18\u001B[0m, in \u001B[0;36mfit\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m     15\u001B[0m w \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m21\u001B[39m,))\n\u001B[0;32m     16\u001B[0m X_transformed \u001B[38;5;241m=\u001B[39m transform_data(X)\n\u001B[1;32m---> 18\u001B[0m regr \u001B[38;5;241m=\u001B[39m \u001B[43mElasticNetCV\u001B[49m(cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, fit_intercept\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, max_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10000\u001B[39m)\n\u001B[0;32m     19\u001B[0m regr\u001B[38;5;241m.\u001B[39mfit(X_transformed, y)\n\u001B[0;32m     20\u001B[0m w \u001B[38;5;241m=\u001B[39m regr\u001B[38;5;241m.\u001B[39mcoef_\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ElasticNetCV' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main function. You don't have to change this\n",
    "if __name__ == \"__main__\":\n",
    "    # Data loading\n",
    "    data = pd.read_csv(\"train.csv\")\n",
    "    y = data[\"y\"].to_numpy()\n",
    "    data = data.drop(columns=[\"Id\", \"y\"])\n",
    "    # print a few data samples\n",
    "    print(data.head())\n",
    "\n",
    "    X = data.to_numpy()\n",
    "    # The function retrieving optimal LR parameters\n",
    "    w = fit(X, y)\n",
    "    # Save results in the required format\n",
    "    np.savetxt(\"./results.csv\", w, fmt=\"%.12f\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x1    x2    x3    x4    x5\n",
      "0  0.02  0.05 -0.09 -0.43 -0.08\n",
      "1 -0.13  0.11 -0.08 -0.29 -0.03\n",
      "2  0.08  0.06 -0.07 -0.41 -0.03\n",
      "3  0.02 -0.12  0.01 -0.43 -0.02\n",
      "4 -0.14 -0.12 -0.08 -0.02 -0.08\n"
     ]
    }
   ],
   "source": [
    "    #prototyping starts here:\n",
    "\n",
    "    # run setup code\n",
    "    data = pd.read_csv(\"train.csv\")\n",
    "    y = data[\"y\"].to_numpy()\n",
    "    data = data.drop(columns=[\"Id\", \"y\"])\n",
    "    # print a few data samples\n",
    "    print(data.head())\n",
    "\n",
    "    X = data.to_numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "700"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(X,axis=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 21 is different from 5)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[93], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m     w \u001B[38;5;241m=\u001B[39m fit(X_train,y_train)\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m#calculate indiviudal RMSE from function put in matrix\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m     RMSE_mat[i] \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_RMSE\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m RMSE_mat\n",
      "Cell \u001B[1;32mIn[61], line 16\u001B[0m, in \u001B[0;36mcalculate_RMSE\u001B[1;34m(w, X, y)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"This function takes test data points (X and y), and computes the empirical RMSE of\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mpredicting y from X using a linear model with weights w.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;124;03mRMSE: float: dim = 1, RMSE value\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     15\u001B[0m td_y \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m---> 16\u001B[0m td_y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\n\u001B[0;32m     18\u001B[0m  \u001B[38;5;66;03m#unsure if the **0.5 is needed or not\u001B[39;00m\n\u001B[0;32m     19\u001B[0m RMSE \u001B[38;5;241m=\u001B[39m mean_squared_error(td_y, td_y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m0.5\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 21 is different from 5)"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "\n",
    "RMSE_mat = np.zeros(n_folds)\n",
    "# and fill all entries in the matrix 'RMSE_mat'\n",
    "\n",
    "Kf = KFold(n_splits=n_folds)\n",
    "\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Kf.split(X)):\n",
    "\n",
    "    #train values in a fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    #test values in a fold\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    #use fit function for w values\n",
    "    w = fit(X_train,y_train)\n",
    "\n",
    "    #calculate indiviudal RMSE from function put in matrix\n",
    "    RMSE_mat[i] = calculate_RMSE(w, X_test, y_test)\n",
    "\n",
    "RMSE_mat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n",
      "(630,)\n"
     ]
    }
   ],
   "source": [
    "#testing for kfold optimizer\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "RMSE_mat = np.zeros(n_folds)\n",
    "# and fill all entries in the matrix 'RMSE_mat'\n",
    "\n",
    "Kf = KFold(n_splits=n_folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(Kf.split(X)):\n",
    "        print(train_index.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "\n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m cross_validation(fit, \u001B[43m_X\u001B[49m, _y, _cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name '_X' is not defined"
     ]
    }
   ],
   "source": [
    "cross_validation(fit, _X, _y, _cv=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEmpty\u001B[0m                                     Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\joblib\\parallel.py:825\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     tasks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ready_batches\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m queue\u001B[38;5;241m.\u001B[39mEmpty:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001B[39;00m\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    831\u001B[0m     \u001B[38;5;66;03m# accordingly to distribute evenly the last items between all\u001B[39;00m\n\u001B[0;32m    832\u001B[0m     \u001B[38;5;66;03m# workers.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\queue.py:168\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qsize():\n\u001B[1;32m--> 168\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mEmpty\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[57], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mElasticNetCV\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     62\u001B[0m )\n\u001B[1;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\joblib\\parallel.py:1048\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1040\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[0;32m   1046\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[0;32m   1047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1048\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1049\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1051\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\joblib\\parallel.py:836\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    833\u001B[0m n_jobs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cached_effective_n_jobs\n\u001B[0;32m    834\u001B[0m big_batch_size \u001B[38;5;241m=\u001B[39m batch_size \u001B[38;5;241m*\u001B[39m n_jobs\n\u001B[1;32m--> 836\u001B[0m islice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mitertools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mislice\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbig_batch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(islice) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    838\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001B[39;00m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# in a different thread depending on the backend and on the value of\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# pre_dispatch and n_jobs.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m---> 59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     62\u001B[0m )\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:268\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m    266\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    267\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m--> 268\u001B[0m         \u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    269\u001B[0m         X,\n\u001B[0;32m    270\u001B[0m         y,\n\u001B[0;32m    271\u001B[0m         scorers,\n\u001B[0;32m    272\u001B[0m         train,\n\u001B[0;32m    273\u001B[0m         test,\n\u001B[0;32m    274\u001B[0m         verbose,\n\u001B[0;32m    275\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    276\u001B[0m         fit_params,\n\u001B[0;32m    277\u001B[0m         return_train_score\u001B[38;5;241m=\u001B[39mreturn_train_score,\n\u001B[0;32m    278\u001B[0m         return_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    279\u001B[0m         return_estimator\u001B[38;5;241m=\u001B[39mreturn_estimator,\n\u001B[0;32m    280\u001B[0m         error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[0;32m    281\u001B[0m     )\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m cv\u001B[38;5;241m.\u001B[39msplit(X, y, groups)\n\u001B[0;32m    283\u001B[0m )\n\u001B[0;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\intro-ml\\lib\\site-packages\\sklearn\\base.py:73\u001B[0m, in \u001B[0;36mclone\u001B[1;34m(estimator, safe)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, \u001B[38;5;28mtype\u001B[39m):\n\u001B[1;32m---> 73\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m     74\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot clone object. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     75\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou should provide an instance of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     76\u001B[0m             \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn estimator instead of a class.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     77\u001B[0m         )\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m     80\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot clone object \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (type \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m): \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     81\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mit does not seem to be a scikit-learn \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     82\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator as it does not implement a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     83\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mget_params\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m method.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mrepr\u001B[39m(estimator), \u001B[38;5;28mtype\u001B[39m(estimator))\n\u001B[0;32m     84\u001B[0m         )\n",
      "\u001B[1;31mTypeError\u001B[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "X_transformed = transform_data(X)\n",
    "n = 10\n",
    "start= 50\n",
    "scores = np.zeros((n,2))\n",
    "k=0\n",
    "for i in range(start, start+n):\n",
    "    regr = ElasticNetCV(cv=i, random_state=0, fit_intercept=False, max_iter = 10000)\n",
    "    regr.fit(X_transformed, y)\n",
    "\n",
    "    scores[k,1] = regr.score(X_transformed,y)\n",
    "    scores[k,0] = i\n",
    "    k += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.26 accuracy with a standard deviation of 27.32\n"
     ]
    }
   ],
   "source": [
    "regro = ElasticNetCV(cv = 56, random_state=0, fit_intercept=False, max_iter = 10000)\n",
    "score = cross_val_score(regro, X, y, cv=100)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.00000000e+01, 1.66910154e-02],\n       [5.10000000e+01, 1.56751893e-02],\n       [5.20000000e+01, 1.66910154e-02],\n       [5.30000000e+01, 1.66910154e-02],\n       [5.40000000e+01, 1.66910154e-02],\n       [5.50000000e+01, 1.66910154e-02],\n       [5.60000000e+01, 1.68780919e-02],\n       [5.70000000e+01, 1.68780919e-02],\n       [5.80000000e+01, 1.68780919e-02],\n       [5.90000000e+01, 1.66910154e-02]])"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "(6,)"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmax(scores[:,1], axis=None), 100)\n",
    "ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "(100,)"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:,1].shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (543409885.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[184], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    solution_luki =\u001B[0m\n\u001B[1;37m                    ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "solution_luki =\n",
    "[ 0.         -0.         -0.          0.          0.         -0.\n",
    "  0.          0.         -0.          0.         -0.4040242  -1.08890313\n",
    " -1.37524395 -0.11770438 -0.32826536 -0.36769822 -0.61963535 -0.63849721\n",
    " -0.41928566 -0.60026965 -0.56232935]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
